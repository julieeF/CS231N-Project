{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2587,
     "status": "ok",
     "timestamp": 1589857145479,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "GrPt_TsDdYnZ",
    "outputId": "d83ac985-0d17-4d66-f7c6-3bfe3ee09199"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# this mounts your Google Drive to the Colab VM.\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\', force_remount=True)\\n\\n# enter the foldername in your Drive where you have saved the unzipped\\n# assignment folder, e.g. \\'cs231n/assignments/assignment3/\\'\\nFOLDERNAME = \\'PROJECT/WITHOUT_NOISE_CLEANUP/\\'\\nassert FOLDERNAME is not None, \"[!] Enter the foldername.\"\\n\\n# now that we\\'ve mounted your Drive, this ensures that\\n# the Python interpreter of the Colab VM can load\\n# python files from within it.\\nimport sys\\nsys.path.append(\\'/content/drive/My Drive/{}\\'.format(FOLDERNAME))\\n\\n# this downloads the CIFAR-10 dataset to your Drive\\n# if it doesn\\'t already exist.\\n#%cd /content/drive/My\\\\ Drive/$FOLDERNAME/\\n#!bash get_datasets.sh\\n\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# this mounts your Google Drive to the Colab VM.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "# enter the foldername in your Drive where you have saved the unzipped\n",
    "# assignment folder, e.g. 'cs231n/assignments/assignment3/'\n",
    "FOLDERNAME = 'PROJECT/WITHOUT_NOISE_CLEANUP/'\n",
    "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
    "\n",
    "# now that we've mounted your Drive, this ensures that\n",
    "# the Python interpreter of the Colab VM can load\n",
    "# python files from within it.\n",
    "import sys\n",
    "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n",
    "\n",
    "# this downloads the CIFAR-10 dataset to your Drive\n",
    "# if it doesn't already exist.\n",
    "#%cd /content/drive/My\\ Drive/$FOLDERNAME/\n",
    "#!bash get_datasets.sh\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6HBuj0nkwZQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os \\nos.chdir(\"/content/drive/My Drive/\")\\nos.chdir(FOLDERNAME)\\n#!bash get_datasets.sh\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os \n",
    "os.chdir(\"/content/drive/My Drive/\")\n",
    "os.chdir(FOLDERNAME)\n",
    "#!bash get_datasets.sh\n",
    "''' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpjXvOssUEwZ"
   },
   "outputs": [],
   "source": [
    "#\"neu_3.0_2.0_2.3333_Whole_Length.png\".split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LjVUrGMmdls7"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install torchsummary\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "#from PIL import ImageFile\n",
    "#ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from collections import defaultdict\n",
    "import cv2\n",
    "import pdb\n",
    "IMG_SIZE = (200,300)\n",
    "\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3sMD9zsIdYne"
   },
   "outputs": [],
   "source": [
    "#dataset_train.__len__\n",
    "#dataset_test.shape\n",
    "#dataset_val.shape\n",
    "\n",
    "#'''test corrupted images'''\n",
    "#data_path = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/images_denoised/session1/\"\n",
    "#dataset_train, dataset_test, dataset_val = get_imagenet_datasets(data_path, \"cpc\")\n",
    "#\n",
    "#print(f\"Number of train samplest {dataset_train.__len__()}\")\n",
    "#print(f\"Number of samples in test split {dataset_test.__len__()}\")\n",
    "#\n",
    "#BATCH_SIZE = 200\n",
    "#\n",
    "#data_loader_train = DataLoader(dataset_train, BATCH_SIZE, shuffle = True)\n",
    "#data_loader_test = DataLoader(dataset_test, BATCH_SIZE, shuffle = True)\n",
    "#\n",
    "#\n",
    "#import matplotlib.pyplot as plt\n",
    "#\n",
    "#fig, axes = plt.subplots(BATCH_SIZE//20,20, figsize=(6,10))\n",
    "#\n",
    "#for batch in data_loader_train:\n",
    "#\n",
    "#    print(f\"Shape of batch['image'] {batch['image'].shape}\")\n",
    "#    print(f\"Shape of batch['cls'] {batch['cls'].shape}\")\n",
    "#\n",
    "#    for i in range(BATCH_SIZE):\n",
    "#\n",
    "#        col = i % 20\n",
    "#        row = i // 20\n",
    "#\n",
    "#        img = batch['image'][i].numpy()\n",
    "#\n",
    "#        axes[row,col].set_axis_off()\n",
    "#        #axes[row,col].set_title(batch['class_name'][i])\n",
    "#        axes[row,col].imshow(np.transpose(img,(1,2,0)))\n",
    "#\n",
    "#    plt.show()\n",
    "#\n",
    "#    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KR5UD4TQdYng"
   },
   "outputs": [],
   "source": [
    "#data_path = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/images/session1/\"\n",
    "#data_path = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/combined_session1_2/\"\n",
    "#data_path1 = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/without_noise_cleanup/session1/\"\n",
    "#data_path2 = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/without_noise_cleanup/session2/\"\n",
    "#data_path3 = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/without_noise_cleanup/session3/\"\n",
    "#data_path4 = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/without_noise_cleanup/session4/\"\n",
    "\n",
    "data_path1 = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/cb_removed/with_noise_cleanup/session1/\"\n",
    "data_path2 = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/cb_removed/with_noise_cleanup/session2/\"\n",
    "data_path3 = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/cb_removed/with_noise_cleanup/session3/\"\n",
    "data_path4 = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/cb_removed/with_noise_cleanup/session4/\"\n",
    "\n",
    "#img_files = os.listdir(\"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/images/session1/\")\n",
    "#img_files = os.listdir(\"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/combined_session1_2/\")\n",
    "#img_files = os.listdir(\"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/cb_removed/with_noise_cleanup/session1/\")\n",
    "\n",
    "#pkl_file = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/without_noise_cleanup/without_noise_cleanup_WHOLE.pkl\"\n",
    "\n",
    "pkl_file = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/4_EMOTIONS/cb_removed/with_noise_cleanup/3sec_time_scale_with_noise_cleaned.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IDdro3xqdYnj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3cESsCFdYnm"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pdb\n",
    "X = []\n",
    "Y = []\n",
    "i = 0\n",
    "#extract_emotion = ['hap','sad','ang','neu','fea', 'exc', 'fru']\n",
    "extract_emotion = ['hap','sad','ang','neu']\n",
    "if 0:\n",
    "    path = [data_path1, data_path2, data_path3, data_path4]\n",
    "    for p_files in path:\n",
    "        for file_name in os.listdir(p_files):\n",
    "                    \n",
    "            print(\"Working on \", i)\n",
    "            i = i+1\n",
    "            #if i >= 7000:\n",
    "            #    break\n",
    "            if \"Whole\" in file_name.split('_'):\n",
    "              print(\"\")\n",
    "              continue\n",
    "            else:\n",
    "              print(\"Working on \", file_name)\n",
    "              #continue\n",
    "            cat = file_name.split('_')[0]\n",
    "            if cat in extract_emotion:\n",
    "                #print(\"\")\n",
    "                if cat == \"hap\":\n",
    "                    cat = 0\n",
    "                if cat == \"sad\":\n",
    "                    cat = 1\n",
    "                if cat == \"ang\":\n",
    "                    cat = 2\n",
    "                if cat == \"neu\":\n",
    "                    cat = 3\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            Y.append(cat)\n",
    "            img = Image.open(p_files+file_name)\n",
    "            img = img.convert('RGB')\n",
    "            tr = transforms.Resize((200,300))\n",
    "            img=tr(img)\n",
    "            \n",
    "            trf = transforms.RandomHorizontalFlip(p=1)\n",
    "            img2 = trf(img)\n",
    "            #pdb.set_trace()\n",
    "            tr = transforms.ToTensor()\n",
    "            \n",
    "            img1 = tr(img)\n",
    "            img2 = tr(img2)\n",
    "            \n",
    "            img1 = np.array(img1)\n",
    "            img2 = np.array(img2)\n",
    "            if cat == \"hap\":\n",
    "                Y.append(cat)\n",
    "                X.append(img1)\n",
    "                Y.append(cat)\n",
    "                X.append(img1)\n",
    "                Y.append(cat)\n",
    "                X.append(img1)\n",
    "                Y.append(cat)\n",
    "                X.append(img1)\n",
    "                Y.append(cat)\n",
    "                X.append(img1)\n",
    "                Y.append(cat)\n",
    "                X.append(img2)\n",
    "                \n",
    "            if cat == \"ang\":\n",
    "                Y.append(cat)\n",
    "                X.append(img1)\n",
    "                Y.append(cat)\n",
    "                X.append(img1)\n",
    "            #X=np.vstack((X,img1))\n",
    "            X.append(img1)\n",
    "            Y.append(cat)\n",
    "            X.append(img2)\n",
    "    \n",
    "            del img1\n",
    "            del img2\n",
    "            del img\n",
    "            del tr\n",
    "\n",
    "    Y = np.asarray(Y)\n",
    "    X = np.asarray(X)\n",
    "    data = {}\n",
    "    data[\"X\"] = X\n",
    "    data[\"Y\"] = Y\n",
    "    with open(pkl_file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        f.close()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4535,
     "status": "error",
     "timestamp": 1589858624846,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "LuTx9Mg6dYnp",
    "outputId": "29f50135-865f-494d-eea0-9ff2ff6896fc"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-43c4c4bae9bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#pkl_file = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/images_denoised/session1_pkl_tensor1.pkl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "assert '.'.join(torch.__version__.split('.')[:2]) == '1.4'\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "#pkl_file = \"/home/mandeep_stanford/cs231n_project/code/pre-processed_data/images_denoised/session1_pkl_tensor1.pkl\"\n",
    "data = pickle.load(open(pkl_file, 'rb'))\n",
    "X = data[\"X\"]\n",
    "Y = data[\"Y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5416,
     "status": "ok",
     "timestamp": 1589857148805,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "eVZQrZkrdYnr",
    "outputId": "97a687f2-74a9-453c-db5f-88437a4112a1"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5286,
     "status": "ok",
     "timestamp": 1589857148805,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "xCGG93zddYnw",
    "outputId": "652d9a67-9847-436e-a810-9f7c5560a2df"
   },
   "outputs": [],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9DcMIkUdYn0"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "total_images = X.shape[0]\n",
    "test_data_images = np.int(total_images*0.2)\n",
    "train_data_images = total_images - test_data_images\n",
    "#X_train = X[0:train_data_images,-1]\n",
    "#y_train = Y[0:train_data_images]\n",
    "#X_test = X[train_data_images:train_data_images+test_data_images, -1]\n",
    "#y_test= Y[train_data_images:train_data_images+test_data_images]\n",
    "\n",
    "#X_train = np.asarray(X_train)\n",
    "#X_test = np.asarray(X_test)\n",
    "#y_train = np.asarray(y_train)\n",
    "#y_test = np.asarray(y_test)\n",
    "\n",
    "#y_train = y_train.reshape((y_train[0]))\n",
    "#y_test = y_test.reshape((y_test[0]))\n",
    "#print(X_train.shape)\n",
    "#print(y_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5167,
     "status": "ok",
     "timestamp": 1589857148806,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "EuiF1RkedYn2",
    "outputId": "b7263a22-3c6c-4123-e999-59a257ee7fd6"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5037,
     "status": "ok",
     "timestamp": 1589857148807,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "fgHlPn3FdYn5",
    "outputId": "c8f02ebe-07ef-43be-fbe1-08864a85f193"
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "keys_array = np.unique(Y)\n",
    "for i in range(len(X)):\n",
    "   ind = np.where(keys_array==Y[i]) \n",
    "   train_data.append([X[i], Y[i]])\n",
    "print(\"DONE\")\n",
    "#dataset = data_utils.TensorDataset(train_data, batch_size=100)\n",
    "print(train_data_images)\n",
    "print(train_data_images+test_data_images)\n",
    "loader_train = DataLoader(train_data, batch_size=64, \n",
    "                          sampler=sampler.SubsetRandomSampler(range(0,train_data_images)))\n",
    "\n",
    "loader_val = DataLoader(train_data, batch_size=64, \n",
    "                        sampler=sampler.SubsetRandomSampler(range(train_data_images, train_data_images+test_data_images)))\n",
    "\n",
    "\n",
    "#for t, (x,y) in enumerate(loader_train):\n",
    "#  print(t, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KxnC-6BsdYn7"
   },
   "outputs": [],
   "source": [
    "print_every = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ii7XMc2M-SHt"
   },
   "outputs": [],
   "source": [
    "def check_train_accuracy(loader, model):\n",
    "    #if loader.dataset.train:\n",
    "    #    print('Checking accuracy on validation set')\n",
    "    #else:\n",
    "    #    print('Checking accuracy on test set')\n",
    "    print('Checking accuracy on TRAIN set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            #pdb.set_trace()\n",
    "            #y = torch.stack(y) #.to(device=device)\n",
    "            #y = y.reshape((x.shape[0]))\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            \n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zI5p3MSIdYn9"
   },
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    #if loader.dataset.train:\n",
    "    #    print('Checking accuracy on validation set')\n",
    "    #else:\n",
    "    #    print('Checking accuracy on test set')\n",
    "    print('Checking accuracy on VAL set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            #pdb.set_trace()\n",
    "            #y = torch.stack(y) #.to(device=device)\n",
    "            #y = y.reshape((x.shape[0]))\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            \n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsGd1KChdYoA"
   },
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    acc = 0\n",
    "    per_epoch_train_accuracy_list = []\n",
    "    per_epoch_test_accuracy_list = []\n",
    "    train_accuracy_list = []\n",
    "    test_accuracy_list = []\n",
    "    loss_list = []\n",
    "    best_model = model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            import pdb\n",
    "            #pdb.set_trace()\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            #y = torch.stack(y) #.to(device=device)\n",
    "            #y = y.reshape((x.shape[0]))\n",
    "            scores = model(x)\n",
    "            \n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            loss_list.append(loss.item())\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "            #pdb.set_trace()\n",
    "            #print(\"IN ITERATION\", t)\n",
    "            if t % print_every == 0:\n",
    "                print('Epoch %d, Iteration %d, loss = %.4f' % (e, t, loss.item()))\n",
    "                #pdb.set_trace()\n",
    "                xx = x.cpu().data.numpy()\n",
    "                yy = y.cpu().data.numpy()\n",
    "                tt_data = []\n",
    "                for i in range(len(xx)):\n",
    "                  ind = np.where(keys_array==Y[i]) \n",
    "                  tt_data.append([xx[i], yy[i]])\n",
    "                \n",
    "                train_d = DataLoader(tt_data, batch_size = 1)\n",
    "                \n",
    "                train_acc = check_train_accuracy(train_d, model)\n",
    "                train_accuracy_list.append(train_acc)\n",
    "                test_acc = check_accuracy_part34(loader_val, model)\n",
    "                test_accuracy_list.append(test_acc)\n",
    "                if test_acc > acc:\n",
    "                  acc = test_acc\n",
    "                  best_model = copy.deepcopy(model)\n",
    "                print()\n",
    "        \n",
    "        e_test_accuracy = check_accuracy_part34(loader_val, model)        \n",
    "        per_epoch_test_accuracy_list.append(e_test_accuracy)     \n",
    "        e_train_accuracy = check_train_accuracy(loader_train, model)        \n",
    "        per_epoch_train_accuracy_list.append(e_train_accuracy)     \n",
    "    return best_model, acc, train_accuracy_list, test_accuracy_list, per_epoch_train_accuracy_list, per_epoch_test_accuracy_list, loss_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1328334,
     "status": "ok",
     "timestamp": 1589833266387,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "Dl5d2fmwdYoD",
    "outputId": "d1e7608e-aa54-491c-938a-66fd67348fb9"
   },
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def flatten(x):\n",
    "        N = x.shape[0] # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        return x.view(N, -1)\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #self.model = nn.LSTM(input_size=(32*25*37),hidden_size=128,num_layers=2,batch_first=True,bidirectional =True, dropout=0.1)\n",
    "        self.model = nn.RNN(input_size=(32*25*37),hidden_size=128,num_layers=2,batch_first=True,bidirectional =True, dropout=0.1)\n",
    "    def forward(self, x):\n",
    "\n",
    "        # From [batches, seqs, seq len, features]\n",
    "        # to [seq len, batch data, features]\n",
    "        x = x.unsqueeze(1)\n",
    "       \n",
    "        # Data is fed to the LSTM\n",
    "        out, _ = self.model(x)\n",
    "\n",
    "        # From [seq len, batch, num_directions * hidden_size]\n",
    "        # to [batches, seqs, seq_len,prediction]\n",
    "        out = out.squeeze(1)\n",
    "\n",
    "\n",
    "        return out\n",
    "\n",
    "#hidden_layer_size = 500\n",
    "#learning_rate = 1e-2\n",
    "\n",
    "#model = nn.Sequential(\n",
    "#    Flatten(),\n",
    "#    nn.Linear(3 * 200 * 300, hidden_layer_size),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(hidden_layer_size, keys_array.shape[0]),\n",
    "#)\n",
    "\n",
    "\n",
    "l1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(12,16), padding=(6,8), stride=1),\n",
    "            nn.ReLU(),\n",
    "            #nn.Conv2d(channel_1, channel_1, kernel_size=5, padding=2, stride=1),\n",
    "            nn.MaxPool2d(2, 2)\n",
    ")\n",
    "\n",
    "#for t, (x, y) in enumerate(loader_train):\n",
    "#            # put model to training mode\n",
    "#            x = x.to(device=device, dtype=dtype)\n",
    "#            import pdb\n",
    "#            pdb.set_trace()\n",
    "#            break\n",
    "    \n",
    "#pdb.set_trace()\n",
    "#h = l1(x)\n",
    "#h.shape\n",
    "\n",
    "l2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 24, kernel_size=(8,12), padding=(4,6), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    ")\n",
    "#h = l2(h)\n",
    "\n",
    "#l3 = nn.Sequential(\n",
    "#            nn.Conv2d(24, 32, kernel_size=(5,7), padding=(2,3), stride=1),\n",
    "#            nn.ReLU(),\n",
    "#            nn.MaxPool2d(2, 2),\n",
    "#            Flatten(),\n",
    "#            LSTM()           \n",
    "#)\n",
    "\n",
    "l3 = nn.Sequential(\n",
    "            nn.Conv2d(24, 32, kernel_size=(5,7), padding=(2,3), stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "            \n",
    ")\n",
    "\n",
    "#l4 = nn.Sequential(\n",
    "#            nn.Conv2d(channel_3, channel_4, kernel_size=3, padding=1, stride=1),\n",
    "#            nn.MaxPool2d(2, 1)\n",
    "#)\n",
    "\n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "hidden_layer_size = keys_array.shape[0]\n",
    "learning_rate = 1e-4 #1e-4   1e-3 looks gud\n",
    "'''\n",
    "model = nn.Sequential(\n",
    "            l1,\n",
    "            l2,\n",
    "            l3,\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, keys_array.shape[0])\n",
    ")\n",
    "'''\n",
    "model = nn.Sequential(\n",
    "            l1,\n",
    "            l2,\n",
    "            l3,\n",
    "            Flatten(),\n",
    "            nn.Linear(32*25*37, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(64, keys_array.shape[0])\n",
    ")\n",
    "\n",
    "\n",
    "# you can use Nesterov momentum in optim.SGD\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, \n",
    "                     betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False) #weight_decay = 0 luks gud. Trying with 0.1\n",
    "\n",
    "\n",
    "#best_model, best_test_acc, train_accuracy_list, test_accuracy_list, loss_list = train_part34(model, optimizer, 2)\n",
    "best_model, best_test_acc, train_accuracy_list, test_accuracy_list, per_epoch_train_accuracy_list, per_epoch_test_accuracy_list, loss_list = train_part34(model, optimizer, 80)\n",
    "print(\"DONE TRAINING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1146,
     "status": "error",
     "timestamp": 1589858476284,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "goWHRw3HuFul",
    "outputId": "209f0e61-475c-427e-da16-96f6bff1572a"
   },
   "outputs": [],
   "source": [
    "torch.save(best_model, \"best_model_RNN_without_noise_cleanup_whole_time_scale_50_epochs\")\n",
    "torch.save(model, \"model_RNN_without_noise_cleanup_whole_time_scale_50_epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIMkqUoMdYoF"
   },
   "outputs": [],
   "source": [
    "print(\"DONE\")\n",
    "per_epoch_train_accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2035,
     "status": "error",
     "timestamp": 1589858608999,
     "user": {
      "displayName": "Mandeep Singh",
      "photoUrl": "",
      "userId": "03930284151741941182"
     },
     "user_tz": 420
    },
    "id": "2VfNH0ZTAU6x",
    "outputId": "d08c77c0-6bac-468d-fc33-e316e333f375"
   },
   "outputs": [],
   "source": [
    "##PLOT LOSS, TRAIN ACCURACY, TEST ACCURACY\n",
    "import matplotlib.pyplot as plt\n",
    "max_train_accuracy = np.repeat(np.max(np.array([train_accuracy_list])),   len(train_accuracy_list))\n",
    "\n",
    "max_test_accuracy = np.repeat(np.max(np.array([test_accuracy_list])),   len(test_accuracy_list))\n",
    "\n",
    "max_p_e_train_accuracy = np.repeat(np.max(np.array([per_epoch_train_accuracy_list])),   len(per_epoch_train_accuracy_list))\n",
    "\n",
    "max_p_e_test_accuracy = np.repeat(np.max(np.array([per_epoch_test_accuracy_list])),   len(per_epoch_test_accuracy_list))\n",
    "\n",
    "# plot the loss history\n",
    "plt.subplot()\n",
    "plt.plot(loss_list)\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot()\n",
    "plt.plot(train_accuracy_list, label='train')\n",
    "plt.plot(test_accuracy_list, label='val')\n",
    "plt.plot(max_train_accuracy, label='max train acc')\n",
    "plt.plot(max_test_accuracy, label='max val acc')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.subplot()\n",
    "plt.plot(per_epoch_train_accuracy_list, label='train')\n",
    "plt.plot(per_epoch_test_accuracy_list, label='val')\n",
    "plt.plot(max_p_e_train_accuracy, label='max train acc')\n",
    "plt.plot(max_p_e_test_accuracy, label='max val acc')\n",
    "plt.title('Per Epoch Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Classification accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5-syI-51dYoH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WzqBPaDdYoJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from resources.plotcm import plot_confusion_matrix\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rdTiyHtyL83r"
   },
   "outputs": [],
   "source": [
    "def check_train_accuracy1(loader, model, for_confusion_matrix=0):\n",
    "    #if loader.dataset.train:\n",
    "    #    print('Checking accuracy on validation set')\n",
    "    #else:\n",
    "    #    print('Checking accuracy on test set')\n",
    "    print('Checking accuracy on TRAIN set')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    true_label_list = []\n",
    "    predicted_label_list = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            true_label_list.append(y.cpu().data.numpy())\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            #pdb.set_trace()\n",
    "            #y = torch.stack(y) #.to(device=device)\n",
    "            #y = y.reshape((x.shape[0]))\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            predicted_label_list.append(preds.cpu().data.numpy())            \n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        if for_confusion_matrix == 1:\n",
    "          return acc, true_label_list, predicted_label_list\n",
    "        else:\n",
    "          return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2WT4du6YMAFr"
   },
   "outputs": [],
   "source": [
    "#best_model1 = torch.load(\"model2\")\n",
    "accuracy, true_label, predicted_label = check_train_accuracy1(loader_train, best_model, for_confusion_matrix=1)\n",
    "true_label = np.concatenate(true_label, axis=None)\n",
    "#print(true_label)\n",
    "\n",
    "predicted_label = np.concatenate(predicted_label, axis=None)\n",
    "#print(predicted_label)\n",
    "\n",
    "emotion_dict = ('hap',\n",
    "                'sad',\n",
    "                'ang',\n",
    "                'neu'\n",
    "                )\n",
    "cm = confusion_matrix(true_label, predicted_label)\n",
    "\n",
    "#t_t = train_set_targets.cpu().data.numpy()\n",
    "#predict = preds.cpu().data.numpy()\n",
    "#t_t = 1 + t_t\n",
    "#predict = 1 + predict\n",
    "\n",
    "#for i in range(t_t.shape[0]):\n",
    "#  print(t_t[i], predict[i])\n",
    "#print(t_t)\n",
    "#print(predict)\n",
    "#print(cm)\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(cm, emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fl8qBVHMoyM"
   },
   "outputs": [],
   "source": [
    "#best_model1 = torch.load(\"model1\")\n",
    "accuracy, true_label, predicted_label = check_train_accuracy1(loader_val, best_model, for_confusion_matrix=1)\n",
    "true_label = np.concatenate(true_label, axis=None)\n",
    "#print(true_label)\n",
    "\n",
    "predicted_label = np.concatenate(predicted_label, axis=None)\n",
    "#print(predicted_label)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_label, predicted_label)\n",
    "\n",
    "#t_t = train_set_targets.cpu().data.numpy()\n",
    "#predict = preds.cpu().data.numpy()\n",
    "#t_t = 1 + t_t\n",
    "#predict = 1 + predict\n",
    "\n",
    "#for i in range(t_t.shape[0]):\n",
    "#  print(t_t[i], predict[i])\n",
    "#print(t_t)\n",
    "#print(predict)\n",
    "#print(cm)\n",
    "plt.figure(figsize=(6,6))\n",
    "plot_confusion_matrix(cm, emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_pIx_vZUybe"
   },
   "outputs": [],
   "source": [
    "accuracy, true_label, predicted_label = check_train_accuracy1(loader_train, model, for_confusion_matrix=1)\n",
    "true_label = np.concatenate(true_label, axis=None)\n",
    "#print(true_label)\n",
    "\n",
    "predicted_label = np.concatenate(predicted_label, axis=None)\n",
    "#print(predicted_label)\n",
    "\n",
    "emotion_dict = ('hap',\n",
    "                'sad',\n",
    "                'ang',\n",
    "                'neu'\n",
    "                )\n",
    "cm = confusion_matrix(true_label, predicted_label)\n",
    "\n",
    "#t_t = train_set_targets.cpu().data.numpy()\n",
    "#predict = preds.cpu().data.numpy()\n",
    "#t_t = 1 + t_t\n",
    "#predict = 1 + predict\n",
    "\n",
    "#for i in range(t_t.shape[0]):\n",
    "#  print(t_t[i], predict[i])\n",
    "#print(t_t)\n",
    "#print(predict)\n",
    "#print(cm)\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_confusion_matrix(cm, emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eX0kZB8JUy1f"
   },
   "outputs": [],
   "source": [
    "#best_model1 = torch.load(\"model1\")\n",
    "accuracy, true_label, predicted_label = check_train_accuracy1(loader_val, model, for_confusion_matrix=1)\n",
    "true_label = np.concatenate(true_label, axis=None)\n",
    "#print(true_label)\n",
    "\n",
    "predicted_label = np.concatenate(predicted_label, axis=None)\n",
    "#print(predicted_label)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_label, predicted_label)\n",
    "\n",
    "#t_t = train_set_targets.cpu().data.numpy()\n",
    "#predict = preds.cpu().data.numpy()\n",
    "#t_t = 1 + t_t\n",
    "#predict = 1 + predict\n",
    "\n",
    "#for i in range(t_t.shape[0]):\n",
    "#  print(t_t[i], predict[i])\n",
    "#print(t_t)\n",
    "#print(predict)\n",
    "#print(cm)\n",
    "plt.figure(figsize=(6,10))\n",
    "plot_confusion_matrix(cm, emotion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Whole_Scale_Without_Noise_Removed_With RNN Model2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
